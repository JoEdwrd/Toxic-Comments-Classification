{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8076,"databundleVersionId":44219,"sourceType":"competition"},{"sourceId":19053,"sourceType":"datasetVersion","datasetId":14154}],"dockerImageVersionId":104,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"_uuid":"e4683e9c-c4c5-46e6-ab82-093ecd941690","_cell_guid":"43d22d64-b591-4b69-82ff-016eb8805b0f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q watermark","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --ignore-installed PyYAML","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext watermark\n%watermark -p torch,pandas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom keras.models import Model\nfrom keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\nfrom keras.callbacks import Callback\nimport warnings\nimport os\n\nwarnings.filterwarnings('ignore')\nos.environ['OMP_NUM_THREADS'] = '4'\n\n# Load data\ntrain = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\nsubmission = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip')\n\n\nfrom transformers import AutoTokenizer\n\nMAX_LEN = 250\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n\n\ntrain_encodings = tokenizer(train[\"comment_text\"].fillna(\"fillna\").tolist(), truncation=True, padding=True, max_length=MAX_LEN)\ntest_encodings = tokenizer(test[\"comment_text\"].fillna(\"fillna\").tolist(), truncation=True, padding=True, max_length=MAX_LEN)\n\nx_train = np.array(train_encodings['input_ids'])\nx_test = np.array(test_encodings['input_ids'])\ny_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n\n\nEMBEDDING_FILE = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\ndef get_coefs(word, *arr): \n    return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n\nword_index = tokenizer.get_vocab()\nmax_features = min(150000, len(word_index) + 1)\nembed_size = 300\nembedding_matrix = np.zeros((max_features, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n\nclass RocAucEvaluation(Callback):\n    def __init__(self, training_data=(), validation_data=(), interval=1):\n        super(Callback, self).__init__()\n        self.interval = interval\n        self.X_train, self.y_train = training_data\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            # Validation metrics\n            y_val_pred = self.model.predict(self.X_val, verbose=0)\n            roc_auc = roc_auc_score(self.y_val, y_val_pred)\n            f1 = f1_score(self.y_val, (y_val_pred > 0.5).astype(int), average='macro')\n            \n            # Training metrics\n            y_train_pred = self.model.predict(self.X_train, verbose=0)\n            roc_auc_train = roc_auc_score(self.y_train, y_train_pred)\n            f1_train = f1_score(self.y_train, (y_train_pred > 0.5).astype(int), average='macro')\n            \n            print(f\"\\nEpoch: {epoch+1}\")\n            print(f\"Training ROC-AUC: {roc_auc_train:.6f}, Training F1: {f1_train:.6f}\")\n            print(f\"Validation ROC-AUC: {roc_auc:.6f}, Validation F1: {f1:.6f}\\n\")\n\n\nfilter_sizes = [1, 2, 3, 5, 7]  \nnum_filters = 64                \n\ndef get_model():    \n    inp = Input(shape=(MAX_LEN, ))\n    x = Embedding(max_features, embed_size, weights=[embedding_matrix], input_length=MAX_LEN)(inp)\n    x = SpatialDropout1D(0.2)(x)\n    x = Reshape((MAX_LEN, embed_size, 1))(x)\n    \n    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), kernel_initializer='normal', activation='elu')(x)\n    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), kernel_initializer='normal', activation='elu')(x)\n    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), kernel_initializer='normal', activation='elu')(x)\n    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size), kernel_initializer='normal', activation='elu')(x)\n    conv_4 = Conv2D(num_filters, kernel_size=(filter_sizes[4], embed_size), kernel_initializer='normal', activation='elu')(x)\n    \n    maxpool_0 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[0] + 1, 1))(conv_0)\n    maxpool_1 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[1] + 1, 1))(conv_1)\n    maxpool_2 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[2] + 1, 1))(conv_2)\n    maxpool_3 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[3] + 1, 1))(conv_3)\n    maxpool_4 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[4] + 1, 1))(conv_4)\n        \n    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3, maxpool_4])   \n    z = Flatten()(z)\n    z = Dropout(0.2)(z)  \n    z = Dense(1024, activation='relu')(z)  \n    z = Dropout(0.2)(z)\n        \n    outp = Dense(6, activation=\"sigmoid\")(z)\n    \n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return model\n\nmodel = get_model()\n\nbatch_size = 512  \nepochs = 5        \n\nX_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.8, random_state=233)\nRocAuc = RocAucEvaluation(training_data=(X_tra, y_tra), validation_data=(X_val, y_val), interval=1)\n\nhist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[RocAuc], verbose=2)\n\ny_pred = model.predict(x_test, batch_size=1024)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}